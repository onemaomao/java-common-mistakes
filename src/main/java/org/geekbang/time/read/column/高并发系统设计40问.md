# 01 | 高并发系统：它的通用设计方法是什么？
Scale-out（横向扩展）
缓存
异步

罗马不是一天建成的，系统的设计也是如此。不同量级的系统有不同的痛点，也就有不同的架构设计的侧重点。
如果都按照百万、千万并发来设计系统，电商一律向淘宝看齐，IM 全都学习微信和 QQ，那么这些系统的命运一定是灭亡。

系统的演进过程应该遵循下面的思路:
最简单的系统设计满足业务需求和流量现状，选择最熟悉的技术体系。
随着流量的增加和业务的变化，修正架构中存在问题的点，如单点问题，横向扩展问题，性能无法满足需求的组件。在这个过程中，选择社区成熟的、团队熟悉的组件帮助我们解决问题，在社区没有合适解决方案的前提下才会自己造轮子。
当对架构的小修小补无法满足需求时，考虑重构、重写等大的调整方式以解决现有的问题。

# 02 | 架构分层：我们为什么一定要这么做？
三层架构示意:表现层、逻辑层、数据访问层
网络分层模型:
    七层:物理层、数据链路层、网络层、传输层、会话层、表示层、应用层
    四层:数据链路层       、网络层、传输层、应用层
Linux文件系统分层:硬件、内核空间、用户空间

分层的好处:专注、复用、容易做横向扩展

如何分层:
分层架构的不足:复杂度的增加,增加网络调用(如果层级独立部署)

# 03 | 系统设计目标（一）：如何提升系统性能？
高并发系统设计的三大目标：高性能、高可用、可扩展
性能优化原则
    首先，性能优化一定不能盲目，一定是问题导向的。
    其次，性能优化也遵循“八二原则”，用 20% 的精力解决 80% 的性能问题。
    再次，性能优化也要有数据支撑。
    最后，性能优化的过程是持续的。
性能的度量指标
    平均值--参考
    最大值
    分位值--实际工作中应用最多
响应时间究竟控制在多长时间比较合适:200ms 是第一个分界点,1s 是另外一个分界点。健康系统的 99 分位值的响应时间通常需要控制在 200ms 之内，而不超过 1s 的请求占比要在 99.99% 以上。

高并发下的性能优化
1. 提高系统的处理核心数
   阿姆达尔定律（Amdahl’s law）
2. 减少单次任务响应时间
   CPU 密集型还是 IO 密集型?
   CPU 密集型系统:通过一些 Profile 工具来找到消耗 CPU 时间最多的方法或者模块，比如 Linux 的 perf、eBPF 等。
   IO 密集型系统:Linux 的工具集+监控
优化方案会随着问题的不同而不同
   
# 04 | 系统设计目标（二）：系统怎样做到高可用？
高可用性（High Availability，HA）指的是系统具备较高的无故障运行的能力。
可用性的度量
MTBF（Mean Time Between Failure）平均故障间隔，代表两次故障的间隔时间，也就是系统正常运转的平均时间。这个时间越长，系统稳定性越高。
MTTR（Mean Time To Repair）故障的平均恢复时间，也可以理解为平均故障时间。这个值越小，故障对于用户的影响越小。
Availability = MTBF / (MTBF + MTTR)
1个9到6个9的年故障和日故障时间

高可用系统设计的思路
1. 系统设计
   failover（故障转移）、超时控制以及降级和限流。
2. 系统运维
   灰度发布、故障演练
   
总结
开发注重的是如何处理故障，关键词是冗余和取舍。
从运维角度来看则更偏保守，注重的是如何避免故障的发生
两者结合起来才能组成一套完善的高可用体系。

# 05 | 系统设计目标（三）：如何让系统易于扩展？
为什么提升扩展性会很复杂
数据库、缓存、依赖的第三方、负载均衡、交换机带宽等等都是系统扩展时需要考虑的因素。

高可扩展性的设计思路
将复杂的问题简单化，这就是我们的思路。
1. 存储层的扩展性
   存储拆分首先考虑的维度是业务维度。垂直
   按照数据特征做水平的拆分。水平
2. 业务层的扩展性
   三个维度：业务纬度，重要性纬度和请求来源纬度。

# 06 | 面试现场第一期：当问到组件实现原理时，面试官是在刁难你吗？

# 07 | 池化技术：如何减少频繁创建数据库连接的性能损耗？
频繁创建连接会造成响应时间慢呢？
tcpdump抓包查看整个 MySQL 的连接过程可以分为两部分：
第一部分是前三个数据包。TCP 的三次握手过程。
第二部分是 MySQL 服务端校验客户端密码的过程。
用连接池预先建立数据库连接
两个最重要的配置:最小连接数和最大连接数。它们控制着从连接池中获取连接的流程:......
如何保证连接池的可用:
1. 启动一个线程来定期检测连接池中的连接是否可用，比如使用连接发送“select 1”的命令给数据库看是否会抛出异常
2. 在获取到连接之后，先校验连接是否可用，如果可用才会执行 SQL 语句。testOnBorrow

用线程池预先创建线程
ThreadPoolExecutor
它们都有一个共同点：它们所管理的对象，无论是连接还是线程，它们的创建过程都比较耗时，也比较消耗系统资源。
所以，我们把它们放在一个池子里统一管理起来，以达到提升性能和资源复用的目的。

# 08 | 数据库优化方案（一）：查询请求增加时，如何做主从分离？
主从读写分离
    大部分系统的访问模型是读多写少，读写请求量的差距可能达到几个数量级。

主从读写的两个技术关键点
1. 主从复制
   binlog
   主从复制的过程:
       从库在连接到主节点时会创建一个 IO 线程，用以请求主库更新的 binlog，并且把接收到的 binlog 信息写入一个叫做 relay log 的日志文件中;
       主库也会创建一个 log dump 线程来发送 binlog 给从库;
       从库还会创建一个 SQL 线程读取 relay log 中的内容，并且在从库中做回放，最终实现主从的一致性。
   并非无限制地增加从库的数量就可以抵抗大量的并发
        随着从库数量增加，从库连接上来的 IO 线程比较多，主库也需要创建同样多的 log dump 线程来处理复制的请求，对于主库资源消耗比较高。同时受限于主库的网络带宽，所以在实际使用中，一般一个主库最多挂 3～5 个从库。
   
   主从复制延迟的缺陷&解决
        数据冗余、使用缓存、查询主库
   主从同步的延迟，是我们排查问题时很容易忽略的一个问题。
2. 如何访问数据库
   第一类以淘宝的 TDDL（ Taobao Distributed Data Layer）为代表，以代码形式内嵌运行在应用程序内部。
   另一类是单独部署的代理层方案，这一类方案代表比较多，如早期阿里巴巴开源的 Cobar，基于 Cobar 开发出来的 Mycat，360 开源的 Atlas，美团开源的基于 Atlas 开发的 DBProxy 等等。

总结
使用主从复制这个技术点时，你一般会考虑两个问题：
1. 主从的一致性和写入性能的权衡，如果你要保证所有从节点都写入成功，那么写入性能一定会受影响；
   如果你只写入主节点就返回成功，那么从节点就有可能出现数据同步失败的情况，从而造成主从不一致，而在互联网的项目中，我们一般会优先考虑性能而不是数据的强一致性。
2. 主从的延迟问题，很多诡异的读取不到数据的问题都可能会和它有关，如果你遇到这类问题不妨先看看主从延迟的数据。
   我们采用的很多组件都会使用到这个技术，比如，Redis 也是通过主从复制实现读写分离；Elasticsearch 中存储的索引分片也可以被复制到多个节点中；写入到 HDFS 中文件也会被复制到多个 DataNode 中。只是不同的组件对于复制的一致性、延迟要求不同，采用的方案也不同。但是这种设计的思想是通用的，是你需要了解的，这样你在学习其他存储组件的时候就能够触类旁通了。
   
# 09 | 数据库优化方案（二）：写入数据量增加时，如何实现分库分表？
如何对数据库做垂直拆分
    垂直拆分的关注点在于业务相关性
    一般是按照业务类型来拆分，核心思想是专库专用，将业务耦合度比较高的表拆分到单独的库中。
如何对数据库做水平拆分
    水平拆分指的是将单一数据表按照某一种规则拆分到多个数据库和多个数据表中，关注点在数据的特点
    1. 按照某一个字段的哈希值做拆分，这种拆分规则比较适用于实体表，比如说用户表，内容表，我们一般按照这些实体表的 ID 字段来拆分。
    2. 另一种比较常用的是按照某一个字段的区间来拆分，比较常用的是时间字段。
解决分库分表引入的问题
    1.分库分表引入的一个最大的问题就是引入了分库分表键，也叫做分区键，也就是我们对数据库做分库分表所依据的字段。
    办法:建立映射
    2.join困难(代码筛选)、count困难(计数的数据单独存储在一张表中或者记录在 Redis 里面)
小结
分库分表原则:
1. 如果在性能上没有瓶颈点那么就尽量不做分库分表；
2. 如果要做，就尽量一次到位，比如说 16 库 64 表就基本能够满足为了几年内你的业务的需求。
3. 很多的 NoSQL 数据库，例如 Hbase，MongoDB 都提供 auto sharding 的特性，如果你的团队内部对于这些组件比较熟悉，有较强的运维能力，那么也可以考虑使用这些 NoSQL 数据库替代传统的关系型数据库。

# 10 | 发号器：如何保证分库分表后ID的全局唯一性？
数据库的主键要如何选择？
1. 使用业务字段作为主键，比如说对于用户表来说，可以使用手机号，email 或者身份证号作为主键。(大部分场景来说并不适用)
2. 使用生成的唯一 ID 作为主键。

基于 Snowflake 算法搭建发号器
    UUID的缺陷:不满足自增(有序)、写入性能、不具备业务含义、耗费空间
    B+ 树存储索引数据，而主键也是一种索引，如果有序只要追加在后面即可，如果无序，需要先做“寻道”找到要写入的位置

    Snowflake 的核心思想:将 64bit 的二进制数字分成若干部分，每一部分都存储有特定含义的数据，比如说时间戳、机器 ID、序列号等等，最终生成全局唯一的有序 ID。
    0不用+41 位的时间戳+10 位的机器 ID+12位序列号
    可以根据实际情况改造，比如:1 位兼容位恒为 0 + 41 位时间信息 + 6 位 IDC 信息（支持 64 个 IDC）+ 6 位业务信息（支持 64 个业务）+ 10 位自增信息（每毫秒支持 1024 个号）

    两种算法的实现方式：
        嵌入到业务代码里，也就是分布在业务服务器中。
        作为独立的服务部署，这也就是我们常说的发号器服务。

    缺点:
        依赖于系统的时间戳，一旦系统时间不准，就有可能生成重复的 ID。
            如果我们发现系统时钟不准，就可以让发号器暂时拒绝发号，直到时钟准确为止。
        如果请求发号器的 QPS 不高，比如说发号器每毫秒只发一个 ID，就会造成生成 ID 的末位永远是 1，那么在分库分表时如果使用 ID 作为分区键就会造成库表分配的不均匀。
            1. 时间戳不记录毫秒而是记录秒，这样在一个时间区间里可以多发出几个号，避免出现分库分表时数据分配不均。
            2. 生成的序列号的起始号可以做一下随机，这一秒是 21，下一秒是 30，这样就会尽量的均衡了。
    
    改造Snowflake:
        一是要让算法中的 ID 生成规则符合自己业务的特点；二是为了解决诸如时间回拨等问题。

# 11 | NoSQL：在高并发场景下，数据库和NoSQL如何做到互补？
NoSQL，No SQL？
    Redis、LevelDB 这样的 KV 存储。
    Hbase、Cassandra 这样的列式存储数据库。
    像 MongoDB、CouchDB 这样的文档型数据库。

使用 NoSQL 提升写入性能
    机械磁盘的两种访问方式：一种是随机 IO；另一种是顺序 IO。
    NoSQL 数据库是怎么解决随机IO的？
        最常见的方案:使用的基于 LSM 树的存储引擎
        核心思想:核心思想就是将随机 IO 变成顺序的 IO，从而提升写入的性能

场景补充
    什么是倒排索引呢？
    将记录中的某些列做分词，然后形成的分词与记录 ID 之间的映射关系。
    Elasticsearch

提升扩展性
    MongoDB 就有三个扩展性方面的特性。
        一是 Replica，也叫做副本集，你可以理解为主从分离，也就是通过将数据拷贝成多份来保证当主挂掉后数据不会丢失。
        二是 Shard，也叫做分片，你可以理解为分库分表，即将数据按照某种规则拆分成多份，存储在不同的机器上。
        三是负载均衡，就是当 MongoDB 发现 Shard 之间数据分布不均匀，会启动 Balancer 进程对数据做重新的分配，最终让不同 Shard Server 的数据可以尽量的均衡。
小结
    1. 在性能方面，NoSQL 数据库使用一些算法将对磁盘的随机写转换成顺序写，提升了写的性能；
    2. 在某些场景下，比如全文搜索功能，关系型数据库并不能高效地支持，需要 NoSQL 数据库的支持；
    3. 在扩展性方面，NoSQL 数据库天生支持分布式，支持数据冗余和数据分片的特性。

# 12 | 缓存：数据库成为瓶颈后，动态数据的查询要如何加速？
什么是缓存:
    凡是位于速度相差较大的两种硬件之间，用于协调两者数据传输速度差异的结构，均可称之为缓存。
    硬件组件的延时情况图
    1. 缓存案例
        Linux的TLB,缓存最近转换过的虚拟地址
        抖音,缓存多个视频
        HTTP 协议,Etag
    2. 缓存与缓冲区
        缓冲区则是一块临时存储数据的区域，这些数据后面会被传输到其他设备上。
        缓冲区更像“消息队列篇”中即将提到的消息队列，用以弥补高速设备和低速设备通信时的速度差。
缓存分类
    静态缓存、分布式缓存和热点本地缓存
缓存的不足
    缓存比较适合于读多写少的业务场景，并且数据最好带有一定的热点属性。
    缓存会给整体系统带来复杂度，并且会有数据不一致的风险。
    缓存通常使用内存作为存储介质，但是内存并不是无限的。
    缓存会给运维也带来一定的成本.

小结
缓存可以有多层
缓存命中率是我们对于缓存最重要的一个监控项，越是热点的数据，缓存的命中率就越高。

缓存不仅仅是一种组件的名字，更是一种设计思想
可以认为任何能够加速读请求的组件和设计方案都是缓存思想的体现。而这种加速通常是通过两种方式来实现：
    使用更快的介质，比方说课程中提到的内存；
    缓存复杂运算的结果，比方说前面 TLB 的例子就是缓存地址转换的结果。

# 13 | 缓存的使用姿势（一）：如何选择缓存的读写策略？
Cache Aside（旁路缓存）策略
Read/Write Through（读穿 / 写穿）策略
Write Back（写回）策略
小结
1.Cache Aside 是我们在使用分布式缓存时最常用的策略，你可以在实际工作中直接拿来使用。
2.Read/Write Through 和 Write Back 策略需要缓存组件的支持，所以比较适合你在实现本地缓存组件的时候使用；
3.Write Back 策略是计算机体系结构中的策略，不过写入策略中的只写缓存，异步写入后端存储的策略倒是有很多的应用场景。

# 14 | 缓存的使用姿势（二）：缓存如何做到高可用？
客户端方案Smart Client
    在客户端配置多个缓存的节点，通过缓存写入和读取算法策略来实现分布式，从而提高缓存的可用性。
    1. 缓存数据如何分片
        Hash 分片算法和一致性 Hash 分片算法两种
    2.Memcached 的主从机制
    3. 多副本

中间代理层方案
    在应用代码和缓存节点之间增加代理层，客户端所有的写入和读取的请求都通过代理层，而代理层中会内置高可用策略，帮助提升缓存系统的高可用。
    Facebook 的Mcrouter，Twitter 的Twemproxy，豌豆荚的Codis
服务端方案
    Redis 2.4 版本后提出的 Redis Sentinel 方案。

# 15 | 缓存的使用姿势（三）：缓存穿透了怎么办？
什么是缓存穿透
从缓存中没有查到数据，而不得不从后端系统（比如数据库）中查询的情况。

缓存穿透的解决方案
    回种空值
        建议你在使用的时候应该评估一下缓存容量是否能够支撑。

使用布隆过滤器
    如何使用布隆过滤器来解决缓存穿透
两个缺陷：
    1. 它在判断元素是否在集合中时是有一定错误几率的，比如它会把不是集合中的元素判断为处在集合中；
        和 Hash 碰撞有关
    2. 不支持删除元素。
        和 Hash 碰撞有关
几个建议：
    1. 选择多个 Hash 函数计算多个 Hash 值，这样可以减少误判的几率；
    2. 布隆过滤器会消耗一定的内存空间，所以在使用时需要评估你的业务场景下需要多大的内存，存储的成本是否可以接受。

“dog-pile effect”（狗桩效应）
    有一个极热点的缓存项，它一旦失效会有大量请求穿透到数据库，这会对数据库造成瞬时极大的压力
    1. 在代码中，控制在某一个热点缓存项失效之后启动一个后台线程，穿透到数据库，将数据加载到缓存中，在缓存未加载之前，所有访问这个缓存的请求都不再穿透而直接返回。
    2. 通过在 Memcached 或者 Redis 中设置分布式锁，只有获取到锁的请求才能够穿透到数据库。
小结
    1. 回种空值是一种最常见的解决思路，实现起来也最简单，如果评估空值缓存占据的缓存空间可以接受，那么可以优先使用这种方案；
    2. 布隆过滤器会引入一个新的组件，也会引入一些开发上的复杂度和运维上的成本。所以只有在存在海量查询数据库中，不存在数据的请求时才会使用，在使用时也要关注布隆过滤器对内存空间的消耗；
    3. 对于极热点缓存数据穿透造成的“狗桩效应”，可以通过设置分布式锁或者后台线程定时加载的方式来解决。

# 16 | CDN：静态资源如何加速？
静态资源加速的考虑点

CDN 的关键技术
1. 如何让用户的请求到达 CDN 节点
   DNS 来帮我们解决域名映射的问题
        域名分级解析示意图
            根DNS、顶级DNS(com,org,cn)
            Local DNS、权威DNS
        www.baidu.com的域名解析全过程
   将用户的请求映射到 CDN 服务器上，是使用 CDN 时需要解决的一个核心的问题，而 CNAME 记录在 DNS 解析过程中可以充当一个中间代理层的角色，可以把将用户最初使用的域名代理到正确的 IP 地址上。
2. 如何找到离用户最近的 CDN 节点
   GSLB（Global Server Load Balance，全局负载均衡）
   两方面的作用：
        负载均衡
        保证流量流经的服务器与流量源头在地缘上是比较接近的

总结：
    1.DNS 技术是 CDN 实现中使用的核心技术，可以将用户的请求映射到 CDN 节点上；
    2.DNS 解析结果需要做本地缓存，降低 DNS 解析过程的响应时间；
    3.GSLB 可以给用户返回一个离着他更近的节点，加快静态资源的访问速度。

# 加餐 | 数据的迁移应该如何做？
如何平滑地迁移数据库中的数据
“双写”方案
    1. 将新的库配置为源库的从库，用来同步数据；
    2. 同时，我们需要改造业务代码，在数据写入的时候，不仅要写入旧库，也要写入新库。
    3. 然后，我们就可以开始校验数据了。(最容易出问题的步骤，迁移数据之前先写好数据校验的工具或者脚本)
    4. 如果一切顺利，我们就可以将读流量切换到新库了。(灰度的方式)
    5. 由于有双写的存在，所以在切换的过程中出现任何的问题，都可以将读写流量随时切换到旧库去，保障系统的性能。
    6. 在观察了几天发现数据的迁移没有问题之后，就可以将数据库的双写改造成只写新库，数据的迁移也就完成了。
    需要考虑的一个重要的因素是：自建机房到云上的专线的带宽和延迟，你需要尽量减少跨专线的读操作，所以在切换读流量的时候，你需要保证自建机房的应用服务器读取本机房的数据库，云上的应用服务器读取云上的数据库。这样在完成迁移之前，只要将自建机房的应用服务器停掉，并且将写入流量都切到新库就可以了。
    好处是：迁移的过程可以随时回滚，将迁移的风险降到了最低。劣势是：时间周期比较长，应用有改造的成本。
级联同步方案
    1. 先将新库配置为旧库的从库，用作数据同步；
    2. 再将一个备库配置为新库的从库，用作数据的备份；
    3. 等到三个库的写入一致后，将数据库的读流量切换到新库；
    4. 然后暂停应用的写入，将业务的写入流量切换到新库（由于这里需要暂停应用的写入，所以需要安排在业务的低峰期）。
    回滚方案也比较简单，可以先将读流量切换到备库，再暂停应用的写入，将写流量切换到备库，这样所有的流量都切换到了备库，也就是又回到了自建机房的环境，就可以认为已经回滚了。
数据迁移时如何预热缓存
    使用副本组预热缓存
    改造副本组方案预热缓存

# 17 | 消息队列：秒杀时如何处理每秒上万次的下单请求？
削去秒杀场景下的峰值写流量
    削峰填谷
通过异步处理简化秒杀请求中的业务流程
    异步处理
解耦实现秒杀系统模块之间松耦合

# 18 | 消息投递：如何保证消息仅仅被消费一次？
消息为什么会丢失
1. 在消息生产的过程中丢失消息
   针对这种情况，建议采用的方案是消息重传
2. 在消息队列中丢失消息
   考虑以集群方式部署 Kafka 服务，通过部署多个副本备份数据，保证消息尽量不丢失。
   权衡ack的选择
3. 在消费的过程中存在消息丢失的可能
    等到消息接收和处理完成之后才更新消息的进度
如何保证消息只被消费一次
1. 什么是幂等
   一件事儿无论做多少次都和做一次产生的结果是一样
2. 在生产、消费过程中增加消息幂等性的保证
    生产过程中的幂等
    消费端的幂等:id存入
        存在的问题:消费过程中消息还没存入，消费者宕机，引入事务机制
    业务层的优化处理:乐观锁
        具体描述:比如给账户增加金额，消息体中将版本号也传递过去，消费端消费
    
# 19 | 消息队列：如何降低消息队列系统中消息的延迟？
如何监控消息延迟
    Kafka 提供了工具叫做“kafka-consumer-groups.sh”
    JMX
减少消息延迟的正确姿势
优化消费代码提升性能--增加消费者的数量
消息队列本身
    顺序读写
    零拷贝技术

# 21 | 系统架构：每秒1万次请求的系统要做服务化拆分吗？

# 22 | 微服务架构：微服务化后，系统架构要如何改造？
微服务拆分的原则
    原则一，做到单一服务内部功能的高内聚，和低耦合。
    原则二，你需要关注服务拆分的粒度，先粗略拆分，再逐渐细化。
    原则三，拆分的过程，要尽量避免影响产品的日常功能迭代，也就是说，要一边做产品功能迭代，一边完成服务化拆分。
    原则四，服务接口的定义要具备可扩展性。
微服务化带来的问题和解决思路
    复杂度:
        跨进程的网络调用
        服务之间的错综复杂的依赖关系
        出现问题难以定位

# 23 | RPC框架：10万QPS下如何实现毫秒级的服务调用？
你所知道的 RPC
如何提升网络传输性能
    五种 I/O 模型：
    同步阻塞 I/O
    同步非阻塞 I/O
    同步多路 I/O 复用
    信号驱动 I/O
    异步 I/O
选择合适的序列化方式
    JSON,Thrift,Protobuf
小结
1. 选择高性能的 I/O 模型，推荐使用同步多路 I/O 复用模型；
2. 调试网络参数，这里面有一些经验值的推荐。比如将 tcp_nodelay 设置为 true，也有一些参数需要在运行中来调试，比如接受缓冲区和发送缓冲区的大小，客户端连接请求缓冲队列的大小（back log）等等；
3. 序列化协议依据具体业务来选择。如果对性能要求不高，可以选择 JSON，否则可以从 Thrift 和 Protobuf 中选择其一。

# 24 | 注册中心：分布式系统如何寻址？
你所知道的服务发现
Nginx把应用服务器的地址配置在了文件中。

注册中的基本功能
其一是提供了服务地址的存储；
其二是当存储内容发生变化时，可以将变更的内容推送给客户端。

服务注册和发现的过程

服务状态管理如何来做
    主动探测
    心跳模式
    
    避免服务节点被过度摘除:如果摘除的节点占到了服务集群节点数的 40%，就停止摘除服务节点，并且给服务的开发同学和，运维同学报警
    通知风暴问题:
        首先，要控制一组注册中心管理的服务集群的规模
        其次，你也可以通过扩容注册中心节点的方式来解决
        再次，你可以规范一下对于注册中心的使用方式，如果只是变更某一个节点，那么只需要通知这个节点的变更信息即可

# 25 | 分布式Trace：横跨几十个分布式组件的慢请求要如何排查？






