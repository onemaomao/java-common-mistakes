开篇词 | 优秀的程序员，你的技术栈中不能只有“增删改查”

预习 | 怎样更好地学习这门课？

01 | 为什么需要消息队列？
哪些问题适合使用消息队列来解决？
1. 异步处理
2. 流量控制
3. 服务解耦

02 | 该如何选择消息队列？
选择消息队列产品的基本标准
    首先，必须是开源的产品
    其次，这个产品必须是近年来比较流行并且有一定社区活跃度的产品
    作为一款及格的消息队列产品，必须具备的几个特性包括
        消息的可靠传递：确保不丢消息；
        Cluster：支持集群，确保不会因为某个节点宕机导致服务不可用，当然也不能丢消息；
        性能：具备足够好的性能，能满足绝大多数场景的性能要求。
可供选择的消息队列产品
    1. RabbitMQ
    2. RocketMQ
    3. Kafka

第二梯队的消息队列
ActiveMQ
ZeroMQ
Pulsar

03 | 消息模型：主题和队列有什么区别？
主题和队列有什么区别？
    队列模型
    发布 - 订阅模型（Publish-Subscribe Pattern）
RabbitMQ 的消息模型
    队列模型
    Exchange
RocketMQ 的消息模型
    标准的发布 - 订阅模型
    RocketMQ 也有队列（Queue）这个概念
    “请求 - 确认”机制很好地保证了消息传递过程中的可靠性，但是，在某一条消息被成功消费之前，下一条消息是不能被消费的，否则就会出现消息空洞，违背了有序性这个原则。
    为了解决这个问题，RocketMQ 在主题下面增加了队列的概念。每个主题包含多个队列，通过多个队列来实现多实例并行生产和消费。
    RocketMQ 中，订阅者的概念是通过消费组（Consumer Group）来体现的。
Kafka 的消息模型
    Kafka 的消息模型和 RocketMQ 是完全一样，队列这个概念的名称不一样，Kafka 中对应的名称是“分区（Partition）”，含义和功能是没有任何区别。

04 | 如何利用事务消息实现分布式事务？
什么是分布式事务？
    ACID
    “残血版”的一致性，比如顺序一致性、最终一致性等等。
    常见的分布式事务实现有 2PC（Two-phase Commit，也叫二阶段提交）、TCC(Try-Confirm-Cancel) 和事务消息。
消息队列是如何实现分布式事务的？
    Kafka 和 RocketMQ 都提供了事务相关功能。
    如何用消息队列来实现分布式事务。流程图
    提交事务消息时失败了怎么办?
        Kafka 的解决方案比较简单粗暴，直接抛出异常，让用户自行处理。
        RocketMQ回查。
RocketMQ 中的分布式事务实现
    增加了事务反查的机制来解决事务消息提交失败的问题。
    为了支撑这个事务反查机制，我们的业务代码需要实现一个反查本地事务状态的接口，告知 RocketMQ 本地事务是成功还是失败。

05 | 如何确保消息不会丢失?
    检测消息丢失的方法
        我们可以利用消息队列的有序性来验证是否有消息丢失。利用拦截器机制。
            Kafka,RocketMQ不保证在 Topic 上的严格顺序，只能保证分区上的消息是有序的，所以我们在发消息的时候必须要指定分区，并且，在每个分区单独检测消息序号的连续性。
            如果Producer是多实例的，由于并不好协调多个 Producer 之间的发送顺序，所以也需要每个 Producer 分别生成各自的消息序号，并且需要附加上 Producer 的标识，在 Consumer 端按照每个 Producer 分别来检测序号的连续性。
            Consumer 实例的数量最好和分区数量一致，做到 Consumer 和分区一一对应，这样会比较方便地在 Consumer 内检测消息序号的连续性。
确保消息可靠传递
1. 生产阶段
   通过最常用的请求确认机制，来保证消息的可靠传递
   在编写发送消息代码时，需要注意，正确处理返回值或者捕获异常，就可以保证这个阶段的消息不会丢失。
2. 存储阶段
   如果对消息的可靠性要求非常高，可以通过配置 Broker 参数来避免因为宕机丢消息。
   对于单个节点的 Broker:将消息写入磁盘后再给 Producer 返回确认响应
   对于多个节点组成的集群:至少将消息发送到 2 个以上的节点，再给客户端回复发送确认响应
3. 消费阶段
   从 Broker 拉取消息后，执行用户的消费业务逻辑，成功后，才会给 Broker 发送消费确认响应
   不要在收到消息后就立即发送消费确认，而是应该在执行完所有消费业务逻辑之后，再发送消费确认。

06 | 如何处理消费过程中的重复消息？
消息重复的情况必然存在
    MQTT 协议中三种传递消息时能够提供的服务质量标准
    At most once: 至多一次。
    At least once: 至少一次。
    Exactly once：恰好一次。
    常用的绝大部分消息队列提供的服务质量都是 At least once，包括 RocketMQ、RabbitMQ 和 Kafka 都是这样。消息队列很难保证消息不重复。
用幂等性解决重复消息问题
从对系统的影响结果来说：At least once + 幂等消费 = Exactly once。
    几种常用的设计幂等操作的方法：
    1. 利用数据库的唯一约束实现幂等
        给转账单 ID 和账户 ID 这两个字段联合起来创建一个唯一约束，这样对于相同的转账单 ID 和账户 ID，表里至多只能存在一条记录。
    2. 为更新的数据设置前置条件
        在发消息时在消息体中带上当前的余额，在消费的时候进行判断数据库中，当前余额是否与消息中的余额相等，只有相等才执行变更操作。
    3. 记录并检查操作
        Token 机制或者 GUID（全局唯一 ID）机制
        涉及顺序性，实现起来比较麻烦。

07 | 消息积压了该如何处理？
优化性能来避免消息积压
1. 发送端性能优化
2. 消费端性能优化
   一定要保证消费端的消费性能要高于生产端的发送性能，这样的系统才能健康的持续运行。
       优化消费业务逻辑
       水平扩容(在扩容 Consumer 的实例数量的同时，必须同步扩容主题中的分区（也叫队列）数量，确保 Consumer 的实例数和分区数量是相等的。)

消息积压了该如何处理？
    要么是发送变快了，要么是消费变慢了。
    大部分消息队列都内置了监控的功能，只要通过监控数据，很容易确定是哪种原因。
    如果短时间内没有足够的服务器资源进行扩容，没办法的办法是，将系统降级，通过关闭一些不重要的业务，减少发送方发送的数据量，最低限度让系统还能正常运转，服务一些重要业务。
    消费失败导致的一条消息反复消费这种情况比较多，这种情况也会拖慢整个系统的消费速度。
    日志+堆栈信息

08 | 答疑解惑（一） : 网关如何接收服务端的秒杀结果？
1. 网关如何接收服务端的秒杀结果？
2. 详解 RocketMQ 和 Kafka 的消息模型
3. 如何实现单个队列的并行消费？
4. 如何保证消息的严格顺序？

09 | 学习开源代码该如何入手？
通过文档来了解开源项目
用以点带面的方式来阅读源码
    带着问题去读源码，最好是带着问题的答案去读源码。

10 | 如何使用异步设计提升系统性能？
异步设计如何提升系统性能？
    1. 同步实现的性能瓶颈
       例子:采用同步实现的方式，整个服务器的所有线程大部分时间都没有在工作，而是都在等待。
    2. 采用异步实现解决等待问题
        例子:在线程模型上由同步顺序调用改为了异步调用和回调的机制。
简单实用的异步框架: CompletableFuture
总结:异步思想就是，当我们要执行一项比较耗时的操作时，不去等待操作结束，而是给这个操作一个命令：“当操作完成后，接下来去执行什么。”

11 | 如何实现高性能的异步网络传输？
    我们开发的绝大多数业务系统，它都是 IO 密集型系统。IO 密集型系统大部分时间都在执行 IO 操作，这个 IO 操作主要包括网络 IO 和磁盘 IO，以及与计算机连接的一些外围设备的访问。
理想的异步网络框架应该是什么样的？
    发送数据的时候同步发送就可以了，没有必要异步。
    同步网络 IO 的模型的力不从心。
使用 Netty 来实现异步网络通信
    真正需要业务代码来实现的就两个部分：一个是把服务初始化并启动起来，还有就是，实现收发消息的业务逻辑 MyHandler。
使用 NIO 来实现异步网络通信

12 | 序列化与反序列化：如何通过网络传输结构化的数据？
    要想使用网络框架的 API 来传输结构化的数据，必须得先实现结构化的数据与字节流之间的双向转换。
你该选择哪种序列化实现？
    权衡这样几个因素：
        序列化后的数据最好是易于人类阅读的；
        实现的复杂度是否足够低；
        序列化和反序列化的速度越快越好；
        序列化后的信息密度越大越好，也就是说，同样的一个结构化数据，序列化之后占用的存储空间越小越好；
实现高性能的序列化和反序列化

13 | 传输协议：应用程序之间对话的语言
如何“断句”？
用双工收发协议提升吞吐量

14 | 内存管理：如何避免内存溢出和频繁的垃圾回收？
自动内存管理机制的实现原理
    申请内存的逻辑
        计算要创建对象所需要占用的内存大小；
        在内存中找一块儿连续并且是空闲的内存空间，标记为已占用；
        把申请的内存地址绑定到对象的引用上，这时候对象就可以使用了。
    内存回收的过程:找出所有可以回收的对象，将对应的内存标记为空闲，然后，还需要整理内存碎片。
        标记阶段：从 GC Root 开始，你可以简单地把 GC Root 理解为程序入口的那个对象，标记所有可达的对象，因为程序中所有在用的对象一定都会被这个 GC Root 对象直接或者间接引用。
        清除阶段：遍历所有对象，找出所有没有标记的对象。这些没有标记的对象都是可以被回收的，清除这些对象，释放对应的内存即可。
为什么在高并发下程序会卡死？

高并发下的内存管理技巧
    优化代码中处理请求的业务逻辑，尽量少的创建一次性对象，特别是占用内存较大的对象
    对于需要频繁使用，占用内存较大的一次性对象，建立对象池
    使用更大内存的服务器
    要从根本上来解决这个问题，办法只有一个，那就是绕开自动垃圾回收机制，自己来实现内存管理。不建议。

15 | Kafka如何实现高性能IO？
使用批量消息提升服务端处理能力
    客户端:攒一波一起发。Kafka 的客户端 SDK 在实现消息发送逻辑的时候，采用了异步批量发送的机制。
    服务端(Broker):不会把一批消息再还原成多条消息，再一条一条地处理，这样太慢了。每批消息都会被当做一个“批消息”来处理。
        在 Broker 整个处理流程中，无论是写入磁盘、从磁盘读出来、还是复制到其他副本这些流程中，批消息都不会被解开，一直是作为一条“批消息”来进行处理的。
    在消费时:消息同样是以批为单位进行传递的，Consumer 从 Broker 拉到一批消息后，在客户端把批消息解开，再一条一条交给用户代码处理。
使用顺序读写提升磁盘 IO 性能
    顺序读写相比随机读写省去了大部分的寻址时间，它只要寻址一次，就可以连续地读写下去，所以说，性能要比随机读写要好很多。
    Kafka 就是充分利用了磁盘的这个特性。
利用 PageCache 加速消息读写
    通俗地说，PageCache 就是操作系统在内存中给磁盘上的文件建立的缓存。无论我们使用什么语言编写的程序，在调用系统的 API 读写文件的时候，并不会直接去读写磁盘上的文件，应用程序实际操作的都是 PageCache，也就是文件在内存中缓存的副本。
    Kafka 在读写消息文件的时候，充分利用了 PageCache 的特性。一般来说，消息刚刚写入到服务端就会被消费，按照 LRU 的“优先清除最近最少使用的页”这种策略，读取的时候，对于这种刚刚写入的 PageCache，命中的几率会非常高。
    大部分情况下，消费读消息都会命中 PageCache，带来的好处有两个：一个是读取的速度会非常快，另外一个是，给写入消息让出磁盘的 IO 资源，间接也提升了写入的性能。
ZeroCopy：零拷贝技术
服务端，处理消费的大致逻辑是这样的：
    首先，从文件中找到消息数据，读到内存中；
    然后，把消息通过网络发给客户端。
        这个过程中，数据实际上做了 2 次或者 3 次复制：
            1.从文件复制数据到 PageCache 中，如果命中 PageCache，这一步可以省掉；
            2.从 PageCache 复制到应用程序的内存空间中，也就是我们可以操作的对象所在的内存；
            3.从应用程序的内存空间复制到 Socket 的缓冲区，这个过程就是我们调用网络应用框架的 API 发送数据的过程。
            2、3 步骤两次复制合并成一次复制。直接从 PageCache 中把数据复制到 Socket 缓冲区中，这样不仅减少一次数据复制，更重要的是，由于不用把数据复制到用户内存空间，DMA 控制器可以直接完成数据复制，不需要 CPU 参与，速度更快。


16 | 缓存策略：如何使用缓存来减少磁盘IO？
    缓存的思想很简单，就是把低速存储的数据，复制一份副本放到高速的存储中，用来加速数据的访问。
选择只读缓存还是读写缓存？
    读写缓存的这种设计，它天然就是不可靠的，是一种牺牲数据一致性换取性能的设计。一般情况下，不推荐你来使用读写缓存。
    为什么 Kafka 可以使用 PageCache 来提升它的性能?
        首先，消息队列它的读写比例大致是 1：1，因为，大部分我们用消息队列都是一收一发这样使用。这种读写比例，只读缓存既无法给写加速，读的加速效果也有限，并不能提升多少性能。
        另外，Kafka 它并不是只靠磁盘来保证数据的可靠性，它更依赖的是，在不同节点上的多副本来解决数据可靠性问题，这样即使某个服务器掉电丢失一部分文件内容，它也可以从其他节点上找到正确的数据，不会丢消息。
        而且，PageCache 这个读写缓存是操作系统实现的，Kafka 只要按照正确的姿势来使用就好了，不涉及到实现复杂度的问题。所以，Kafka 其实在设计上，充分利用了 PageCache 这种读写缓存的优势，并且规避了 PageCache 的一些劣势，达到了一个非常好的效果。
        和 Kafka 一样，大部分其他的消息队列，同样也会采用读写缓存来加速消息写入的过程，只是实现的方式都不一样。
保持缓存数据新鲜
    比较简单的方法就是，定时将磁盘上的数据同步到缓存中.
    一种更简单的方法，我们从来不去更新缓存中的数据，而是给缓存中的每条数据设置一个比较短的过期时间，数据过期以后即使它还存在缓存中，我们也认为它不再有效，需要从磁盘上再次加载这条数据，这样就变相地实现了数据更新。
缓存置换策略
    在内存有限的情况下，要优先缓存哪些数据，让缓存的命中率最高。
    命中率最高的置换策略，一定是根据你的业务逻辑，定制化的策略。
    LRU 的算法原理非常简单，它总是把最长时间未被访问的数据置换出去。
    Kafka 使用的 PageCache，是由 Linux 内核实现的，它的置换算法的就是一种 LRU 的变种算法：LRU 2Q。

17 | 如何正确使用锁保护共享数据，协调异步线程？
    锁的原理是这样的：任何时间都只能有一个线程持有锁，只有持有锁的线程才能访问被锁保护的资源。
    避免滥用锁
        如果能不用锁，就不用锁；如果你不确定是不是应该用锁，那也不要用锁。
        第一，加锁和解锁过程都是需要 CPU 时间的，这是一个性能的损失。
        第二，如果对锁使用不当，很容易造成死锁，导致整个程序“卡死”，这是非常严重的问题。
    锁的用法
        在访问共享资源之前，先获取锁。
        如果获取锁成功，就可以访问共享资源了。
        最后，需要释放锁，以便其他线程继续访问共享资源。使用完锁，一定要释放它。
    如何避免死锁？
        再次强调一下，避免滥用锁，程序里用的锁少，写出死锁 Bug 的几率自然就低。
        对于同一把锁，加锁和解锁必须要放在同一个方法中，这样一次加锁对应一次解锁，代码清晰简单，便于分析问题。
        尽量避免在持有一把锁的情况下，去获取另外一把锁，就是要尽量避免同时持有多把锁。
        如果需要持有多把锁，一定要注意加解锁的顺序，解锁的顺序要和加锁顺序相反。比如，获取三把锁的顺序是 A、B、C，释放锁的顺序必须是 C、B、A。
        给你程序中所有的锁排一个顺序，在所有需要加锁的地方，按照同样的顺序加解锁。
    使用读写锁要兼顾性能和安全性

18 | 如何用硬件同步原语（CAS）替代锁？
    什么是硬件同步原语？
        硬件同步原语（Atomic Hardware Primitives）是由计算机硬件提供的一组原子操作，我们比较常用的原语主要是 CAS 和 FAA 这两种。
    CAS 版本的账户服务
    CAS和FAA的操作示例
    耗费 CPU 资源的，因为在 for 循环中，如果赋值不成功，是会立即进入下一次循环没有等待的。

19 | 数据压缩：时间换空间的游戏
    数据压缩不仅能节省存储空间，还可以用于提升网络传输性能。
    什么情况适合使用数据压缩？
        压缩它的本质是资源的置换，是一个时间换空间，或者说是 CPU 资源换存储资源的游戏。
    应该选择什么压缩算法？
        目前常用的压缩算法包括：ZIP，GZIP，SNAPPY，LZ4 等等。选择压缩算法的时候，主要需要考虑数据的压缩率和压缩耗时。一般来说，压缩率越高的算法，压缩耗时也越高。如果是对性能要求高的系统，可以选择压缩速度快的算法，比如 LZ4；如果需要更高的压缩比，可以考虑 GZIP 或者压缩率更高的 XZ 等算法。
    如何选择合适的压缩分段？
        ......
    Kafka 是如何处理消息压缩的？
        首先，Kafka 是否开启压缩，这是可以配置，它也支持配置使用哪一种压缩算法。
        在开启压缩时，Kafka 选择一批消息一起压缩，每一个批消息就是一个压缩分段。使用者也可以通过参数来控制每批消息的大小。
        在服务端不用解压，就不会耗费服务端宝贵的 CPU 资源，同时还能获得压缩后，占用传输带宽小，占用存储空间小的这些好处，这是一个非常聪明的设计。

20 | RocketMQ Producer源码分析：消息生产的实现过程
从单元测试看 Producer API 的使用
    org.apache.rocketmq.client.producer.DefaultMQProducerTest
    RockectMQ 的 Producer 入口类为“org.apache.rocketmq.client.producer.DefaultMQProducer”
    RocketMQ 使用了一个设计模式：门面模式（Facade Pattern）
    有的时候，我们的实现分散在很多的内部类中，不方便用接口来对外提供服务，你就可以仿照 RocketMQ 的这种方式，使用门面模式来隐藏内部实现，对外提供服务。
补充rocketmq的设计文档
    https://github.com/apache/rocketmq/blob/master/docs/cn/design.md
启动过程
    启动过程的实现：
        通过一个单例模式（Singleton Pattern）的 MQClientManager 获取 MQClientInstance 的实例 mQClientFactory，没有则自动创建新的实例；
        在 mQClientFactory 中注册自己；
        启动 mQClientFactory；
        给所有 Broker 发送心跳。
    几个重要类的职责
        DefaultMQProducerImpl：Producer 的内部实现类，大部分 Producer 的业务逻辑，也就是发消息的逻辑，都在这个类中。
        MQClientInstance：这个类中封装了客户端一些通用的业务逻辑，无论是 Producer 还是 Consumer，最终需要与服务端交互时，都需要调用这个类中的方法；
        MQClientAPIImpl：这个类中封装了客户端服务端的 RPC，对调用者隐藏了真正网络通信部分的具体实现；
        NettyRemotingClient：RocketMQ 各进程之间网络通信的底层实现类。
消息发送过程
    在 Producer 的接口 MQProducer 中，定义了 19 个不同参数的发消息的方法，按照发送方式不同可以分成三类：
        单向发送（Oneway）：发送消息后立即返回，不处理响应，不关心是否发送成功；
        同步发送（Sync）：发送消息后等待响应；
        异步发送（Async）：发送消息后立即返回，在提供的回调方法中处理响应。
异步发送的实现方法"DefaultMQProducerImpl#send()"
选择哪个队列发送由 MessageQueueSelector#select 方法决定。在这里 RocketMQ 使用了策略模式（Strategy Pattern），来解决不同场景下需要使用不同的队列选择算法问题。

21 | Kafka Consumer源码分析：消息消费的实现过程
Kafka 的 Consumer 入口:https://kafka.apache.org/10/javadoc/?org/apache/kafka/clients/consumer/KafkaConsumer.html
    org.apache.kafka.clients.consumer.KafkaConsumer
        Consumer 消费的最简代码示例的主要流程：
        设置必要的配置信息，包括：起始连接的 Broker 地址，Consumer Group 的 ID，自动提交消费位置的配置和序列化配置；
        创建 Consumer 实例；
        订阅了 2 个 Topic：foo 和 bar；
        循环拉取消息并打印在控制台上。
订阅过程如何实现？
    org.apache.kafka.clients.consumer.KafkaConsumer#subscribe
    订阅的主流程主要更新了两个属性：一个是订阅状态 subscriptions，另一个是更新元数据中的 topic 信息。
    subscribe() 方法的实现有一个非常值得大家学习的地方：就是开始的 acquireAndEnsureOpen() 和 try-finally release()
    Kafka“主动检测不支持的情况并抛出异常，避免系统产生不可预期的行为”这种模式，对于增强的系统的健壮性是一种非常有效的做法。
    总结一下：在订阅的实现过程中，Kafka 更新了订阅状态 subscriptions 和元数据 metadata 中的相关 topic 的一些属性，将元数据状态置为“需要立即更新”，但是并没有真正发送更新元数据的请求，整个过程没有和集群有任何网络数据交换。

拉取消息的过程如何实现？
    org.apache.kafka.clients.consumer.KafkaConsumer#poll
    主要是先后调用了 2 个私有方法：
        updateAssignmentMetadataIfNeeded(): 更新元数据。
        pollForFetches()：拉取消息。
    pollForFetches() 的实现。
        如果缓存里面有未读取的消息，直接返回这些消息；
        构造拉取消息请求，并发送；
        发送网络请求并拉取消息，等待直到有消息返回或者超时；
        返回拉到的消息。

22 | Kafka和RocketMQ的消息复制实现的差异点在哪？
消息复制面临什么问题？
    目前并没有一种完美的实现方案能够兼顾高性能、高可用和一致性。
RocketMQ 如何实现复制？
    一种是异步复制，消息先发送到主节点上，就返回“写入成功”，然后消息再异步复制到从节点上。
    另外一种方式是同步双写，消息同步双写到主从节点上，主从都写成功，才返回“写入成功”。
    异步复制的方式会不会丢消息?
        不会丢消息。在 RocketMQ 中，Broker 的主从关系是通过配置固定的，不支持动态切换。牺牲了可用性，换取了比较好的性能和数据一致性。
    如何解决可用性的问题
        支持把一个主题分布到多对主从节点上去，每对主从节点中承担主题中的一部分队列，如果某个主节点宕机了，会自动切换到其他主节点上继续发消息，这样既解决了可用性的问题，还可以通过水平扩容来提升 Topic 总体的性能。
    面临的问题
        在需要保证消息严格顺序的场景下，由于在主题层面无法保证严格顺序，所以必须指定队列来发送消息，对于任何一个队列，它一定是落在一组特定的主从节点上，如果这个主节点宕机，其他的主节点是无法替代这个主节点的，否则就无法保证严格顺序。在这种复制模式下，严格顺序和高可用只能选择一个。
    引入 Dledger，使用新的复制方式，可以很好地解决这个问题。
        在写入消息的时候，要求至少消息复制到半数以上的节点之后，才给客户端返回写入成功，并且它是支持通过选举来动态切换主节点的。
        举例说明&不足之处
Kafka 是如何实现复制的？
    Kafka 中，复制的基本单位是分区。每个分区的几个副本之间，构成一个小的复制集群，Broker 只是这些分区副本的容器，所以 Kafka 的 Broker 是不分主从的。
    分区的多个副本中也是采用一主多从的方式。
    ISR（In Sync Replicas)保持数据同步的副本，数量是可配的，但需要注意的是，这个 ISR 中是包含主节点的。
    使用 ZooKeeper 来监控每个分区的多个节点，如果发现某个分区的主节点宕机了，Kafka 会利用 ZooKeeper 来选出一个新的主节点，这样解决了可用性的问题。
    默认情况下，如果所有的 ISR 节点都宕机了，分区就无法提供服务了。你也可以选择配置成让分区继续提供服务，这样只要有一个节点还活着，就可以提供服务，代价是无法保证数据一致性，会丢消息。

23 | RocketMQ客户端如何在集群中找到正确的节点？
NameServer 是如何提供服务的？
    在 RocketMQ 集群中，NameServer 是如何配合 Broker、生产者和消费者一起工作图
NameServer 的总体结构
    排除 KV 读写相关的类之后，一共只有 6 个类
    NamesrvStartup：程序入口。
    NamesrvController：NameServer 的总控制器，负责所有服务的生命周期管理。
    RouteInfoManager：NameServer 最核心的实现类，负责保存和管理集群路由信息。
    BrokerHousekeepingService：监控 Broker 连接状态的代理类。
    DefaultRequestProcessor：负责处理客户端和 Broker 发送过来的 RPC 请求的处理器。
    ClusterTestRequestProcessor：用于测试的请求处理器。
NameServer 如何处理 Broker 注册的路由信息？
    NameServer 处理 Broker 和客户端所有 RPC 请求的入口方法是：“DefaultRequestProcessor#processRequest”
客户端如何寻找 Broker？
    对于客户端来说，无论是生产者还是消费者，通过主题来寻找 Broker 的流程是一样的，使用的也是同一份实现。
    NameServer 处理客户端请求和处理 Broker 请求的流程是一样的，都是通过路由分发器将请求分发的对应的处理方法中，RouteInfoManager#pickupTopicRouteData：
    流程是这样的：
        初始化返回的 topicRouteData 后，获取读锁。
        在 topicQueueTable 中获取主题对应的队列信息，并写入返回结果中。
        遍历队列，找出相关的所有 BrokerName。
        遍历这些 BrokerName，从 brokerAddrTable 中找到对应的 BrokerData，并写入返回结果中。
        释放读锁并返回结果。

24 | Kafka的协调服务ZooKeeper：实现分布式系统的“瑞士军刀”
ZooKeeper 的作用是什么？
    分布式的协调服务框架，主要用来解决分布式集群中，应用系统需要面对的各种通用的一致性问题。
    最核心的功能是，它提供了一个分布式的存储系统，数据的组织方式类似于 UNIX 文件系统的树形结构。
    ZNode
    临时节点
    订阅 ZNode 状态变化的通知机制：Watcher
Kafka 在 ZooKeeper 中保存了哪些信息？
    图
    /brokers/ids/[0...N]:Kafka 的 Broker 信息,每个临时节点对应着一个在线的 Broker,
    /brokers/topics/:节点下面的每个子节点都是一个主题
    /brokers/topics/topicA下面还有pattitions子节点
    pattitions/0-N,每个分区节点下面是一个名为 state 的临时节点，节点中保存着分区当前的 leader 和所有的 ISR 的 BrokerID。这个 state 临时节点是由这个分区当前的 Leader Broker 创建的。如果这个分区的 Leader Broker 宕机了，对应的这个 state 临时节点也会消失，直到新的 Leader 被选举出来，再次创建 state 临时节点。
    Kafka 客户端如何找到对应的 Broker？
        先根据主题和队列，找到分区对应的 state 临时节点(state 节点中保存了这个分区 Leader 的 BrokerID)
        拿到这个 Leader 的 BrokerID 后，再去找到 BrokerID 对应的临时节点，就可以获取到 Broker 真正的访问地址了。

25 | RocketMQ与Kafka中如何实现事务？
RocketMQ 的事务是如何实现的？
    org.apache.rocketmq.client.impl.producer.DefaultMQProducerImpl#sendMessageInTransaction
Kafka 的事务和 Exactly Once 可以解决什么问题？
    RocketMQ 中的事务，它解决的问题是，确保执行本地事务和发消息这两个操作，要么都成功，要么都失败。并且，RocketMQ 增加了一个事务反查的机制，来尽量提高事务执行的成功率和数据一致性。
    而 Kafka 中的事务，它解决的问题是，确保在一个事务中发送的多条消息，要么都成功，要么都失败。
    注意，这里面的多条消息不一定要在同一个主题和分区中，可以是发往多个主题和分区的消息。
    当然，你可以在 Kafka 的事务执行过程中，加入本地事务，来实现和 RocketMQ 中事务类似的效果，但是 Kafka 是没有事务反查机制的。
    Kafka 中的 Exactly Once 解决的是，在流计算中，用 Kafka 作为数据源，并且将计算结果保存到 Kafka 这种场景下，数据从 Kafka 的某个主题中消费，在计算集群中计算，再把计算结果保存在 Kafka 的其他主题中。这样的过程中，保证每条消息都被恰好计算一次，确保计算结果正确。
    Kafka 的 Exactly Once 机制，是为了解决在“读数据 - 计算 - 保存结果”这样的计算过程中数据不重不丢，而不是我们通常理解的使用消息队列进行消息生产消费过程中的 Exactly Once。
Kafka 的事务是如何实现的？
    实现原理和 RocketMQ 的事务是差不多的，都是基于两阶段提交来实现的。
    Kafka 事务的实现流程图
        当我们开启事务的时候，生产者会给协调者发一个请求来开启事务，协调者在事务日志中记录下事务 ID。
        生产者在发送消息之前，还要给协调者发送请求，告知发送的消息属于哪个主题和分区，这个信息也会被协调者记录在事务日志中。
        接下来，生产者就可以像发送普通消息一样来发送事务消息，这里和 RocketMQ 不同的是，RocketMQ 选择把未提交的事务消息保存在特殊的队列中，而 Kafka 在处理未提交的事务消息时，和普通消息是一样的，直接发给 Broker，保存在这些消息对应的分区中，Kafka 会在客户端的消费者中，暂时过滤未提交的事务消息。
        消息发送完成后，生产者给协调者发送提交或回滚事务的请求，由协调者来开始两阶段提交，完成事务。
            第一阶段，协调者把事务的状态设置为“预提交”，并写入事务日志。到这里，实际上事务已经成功了，无论接下来发生什么情况，事务最终都会被提交。
            第二阶段，协调者在事务相关的所有分区中，都会写一条“事务结束”的特殊消息，当 Kafka 的消费者，也就是客户端，读到这个事务结束的特殊消息之后，它就可以把之前暂时过滤的那些未提交的事务消息，放行给业务代码进行消费了。
        最后，协调者记录最后一条事务日志，标识这个事务已经结束了。

26 | MQTT协议：如何支持海量的在线IoT设备?
    MQTT 和其他消息队列的传输协议有什么不同？
    如何选择 MQTT 产品？
    MQTT 集群如何支持海量在线的 IoT 设备？
    总结

27 | Pulsar的存储计算分离设计：全新的消息队列设计思路
Pulsar 的架构和其他消息队列有什么不同？
    消息数据保存在 BookKeeper 中，元数据保存在 ZooKeeper 中
        Broker 是无状态的（Stateless）。也就是说，在 Pulsar 的 Broker 中既不保存元数据，也不存储消息。
        BookKeeper 的存储单元是 Ledger。 Ledger 就是一段 WAL（Write Ahead Log）。
存储计算分离的设计有哪些优点？
    存储计算分离有什么优点
        无状态节点组成的集群，管理、调度都变得非常简单
        计算节点的开发者来说，可以专注于计算业务逻辑开发，而不需要关注像数据一致性、数据可靠性、故障恢复和数据读写性能等等这些比较麻烦的存储问题，极大地降低了开发难度，提升了开发效率。
存储计算分离这种设计的缺点
    BookKeeper 依然要解决数据一致性、节点故障转移、选举、数据复制等等这些问题。
    性能也会有一些损失


